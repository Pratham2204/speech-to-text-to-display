{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from datetime import datetime\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Pratham\n",
      "[nltk_data]     jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Pratham\n",
      "[nltk_data]     jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Pratham jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download the NLTK tagger if necessary\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "# Define the list of keywords to extract\n",
    "keyword_list = [\"eyebrows\", \"eyes\", \"hair\", \"head\", \"lips\", \"mustache\", \"nose\"]\n",
    "\n",
    "# Define the path to the image folder\n",
    "image_folder = \"../speech-to-text/images\"\n",
    "\n",
    "# Define the path to the feedback file\n",
    "feedback_file = \"../speech-to-text/feedback.txt\"\n",
    "\n",
    "#adjectives list\n",
    "adjective_list = list(wn.all_eng_synsets(wn.ADJ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjective_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hair', 'head', 'hair', 'hair', 'lips', 'Eyes', 'eyes', 'eyebrows', 'nose', 'Nose']\n"
     ]
    }
   ],
   "source": [
    "# Open the \"op.txt\" file and read the latest line\n",
    "with open(\"op.txt\", \"r\") as file:\n",
    "    line = file.readlines()[-1].strip()\n",
    "\n",
    "# Define a regular expression to match adjectives\n",
    "adj_regex = re.compile(r\"\\b(?:\" + \"|\".join([adj.name() for adj in adjective_list]) + r\")\\b\", re.IGNORECASE)\n",
    "\n",
    "# Tokenize the sentence into words and tags\n",
    "tagged_words = nltk.pos_tag(word_tokenize(line))\n",
    "\n",
    "# Initialize empty lists for adjectives and keywords\n",
    "adjectives = []\n",
    "keywords = []\n",
    "\n",
    "# Loop through each word and tag\n",
    "for i, (word, tag) in enumerate(tagged_words):\n",
    "    # Check if the word is a keyword\n",
    "    if word.lower() in keyword_list:\n",
    "        # Check if there is an adjective before this keyword\n",
    "        if i > 0 and tagged_words[i-1][1] in [\"JJ\", \"JJR\", \"JJS\"]:\n",
    "            # Add the adjective and keyword to their respective lists\n",
    "            adjectives.append(tagged_words[i-1][0])\n",
    "            keywords.append(word)\n",
    "\n",
    "\n",
    "print(keywords)\n",
    "\n",
    "#In this code, we first define the list of keywords to extract. We then download the NLTK tagger if necessary and tokenize the sentence into words and tags using the pos_tag function.\n",
    "\n",
    "#Next, we initialize empty lists for adjectives and keywords. We then loop through each word and tag, and check if the word is a keyword. If the word is a keyword, we check if there is an adjective before this keyword. If there is, we add the adjective and keyword to their respective lists.\n",
    "\n",
    "#After that, we combine the adjectives and keywords into phrases, just as in the previous code.\n",
    "\n",
    "#Finally, we define the path to the image folder and loop through each phrase. For each phrase, we get the keyword from the phrase and define the path to the subfolder. We then search for the image file in the subfolder using the os.listdir function. If the image file is found, we combine the subfolder path and the image file name and display the image using the PIL library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['short', 'oval', 'curly', 'long', 'bold', 'tired', 'sharp', 'solid', 'narrow', 'long']\n"
     ]
    }
   ],
   "source": [
    "print(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original list:  ['short hair', 'oval head', 'curly hair', 'long hair', 'bold lips', 'tired Eyes', 'sharp eyes', 'solid eyebrows', 'narrow nose', 'long Nose']\n",
      "Final list:  ['long Nose', 'solid eyebrows', 'sharp eyes', 'bold lips', 'long hair', 'oval head']\n"
     ]
    }
   ],
   "source": [
    "# # Combine the adjectives and keywords into phrases\n",
    "phrases = [\" \".join(adj_keyword) for adj_keyword in zip(adjectives, keywords) if adj_keyword]\n",
    "print(\"Original list: \", phrases)\n",
    "\n",
    "# for phrase in phrases:\n",
    "#     if 'hair' in phrase:\n",
    "#         phrases.remove(phrase)\n",
    "#         break\n",
    "# print(phrases)\n",
    "\n",
    "latest_phrases = {}\n",
    "\n",
    "for i, phrase in enumerate(phrases):\n",
    "    for keyword in keyword_list:\n",
    "        if keyword in phrase.lower():\n",
    "            if keyword not in latest_phrases or i > latest_phrases[keyword][1]:\n",
    "                latest_phrases[keyword] = (phrase, i)\n",
    "\n",
    "latest_phrases_list = [x[0] for x in sorted(latest_phrases.values(), key=lambda x: x[1], reverse=True)]\n",
    "print(\"Final list: \", latest_phrases_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected list:  ['short hair', 'tired Eyes', 'curly hair', 'narrow nose']\n"
     ]
    }
   ],
   "source": [
    "difference = set(phrases) - set(latest_phrases_list)\n",
    "rejected_phrases_list = list(difference)\n",
    "print(\"Rejected list: \", rejected_phrases_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image present for phrase: sharp eyes\n",
      "Image present for phrase: long hair\n",
      "Image present for phrase: oval head\n"
     ]
    }
   ],
   "source": [
    "# Loop through each phrase and display the corresponding image\n",
    "for phrase in latest_phrases_list:\n",
    "    # Get the keyword from the phrase\n",
    "    keyword = phrase.split()[-1]\n",
    "    # Define the path to the subfolder\n",
    "    subfolder = os.path.join(image_folder, keyword)\n",
    "    # Search for the image file in the subfolder\n",
    "    for file in os.listdir(subfolder):\n",
    "        if phrase.lower() in file.lower():\n",
    "            # Combine the subfolder path and the image file name\n",
    "            image_path = os.path.join(subfolder, file)\n",
    "            # Display the image\n",
    "            Image.open(image_path).show()\n",
    "            # Print a message that the image is present for this phrase\n",
    "            print(f\"Image present for phrase: {phrase}\")\n",
    "            # Exit the loop since we found the image\n",
    "            break\n",
    "    else:\n",
    "        # Image not found, append the phrase to the feedback file\n",
    "        with open(feedback_file, \"a\") as file:\n",
    "            file.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {phrase} (image not found in {subfolder})\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image present for phrase: short hair\n",
      "Image present for phrase: tired Eyes\n"
     ]
    }
   ],
   "source": [
    "for phrase in rejected_phrases_list:\n",
    "    # Get the keyword from the phrase\n",
    "    keyword = phrase.split()[-1]\n",
    "    # Define the path to the subfolder\n",
    "    subfolder = os.path.join(image_folder, keyword)\n",
    "    # Search for the image file in the subfolder\n",
    "    image_found = False\n",
    "    for file in os.listdir(subfolder):\n",
    "        if phrase.lower() in file.lower():\n",
    "            # Combine the subfolder path and the image file name\n",
    "            image_path = os.path.join(subfolder, file)\n",
    "            # Display the image\n",
    "            # Image.open(image_path).show()\n",
    "            # Print a message that the image is present for this phrase\n",
    "            print(f\"Image present for phrase: {phrase}\")\n",
    "            # Set the flag to True\n",
    "            image_found = True\n",
    "            # Exit the loop since we found the image\n",
    "            break\n",
    "    # If the image was not found, append the phrase to the feedback file\n",
    "    if not image_found:\n",
    "        with open(feedback_file, \"a\") as file:\n",
    "            file.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {phrase} (image not found in {subfolder})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
